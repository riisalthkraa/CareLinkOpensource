# ğŸš€ QUICK START - CareLink avec Modules MatchPro IA

## âœ… CE QUI EST DÃ‰JÃ€ FAIT

Les 5 modules sont **100% implÃ©mentÃ©s** :

1. âœ… **Chiffrement AES-256** â†’ ClÃ©s API sÃ©curisÃ©es
2. âœ… **Multi-Provider PrioritÃ©s** â†’ Fallback automatique
3. âœ… **Backend Python ML** â†’ Sentence-BERT
4. âœ… **Dashboard Temps RÃ©el** â†’ Auto-refresh 30s
5. âœ… **Tracking API** â†’ CoÃ»ts et usage

**Fichiers modifiÃ©s/crÃ©Ã©s :** 10 fichiers, ~1700 lignes de code

---

## ğŸ¯ TESTER GEMINI MAINTENANT

### Votre clÃ© Gemini fonctionne !

**ClÃ© API :** `AIzaSyBedSTR_DeOiWuGB0Fj33OprBfGjHewzrY`
**ModÃ¨le recommandÃ© :** `gemini-2.5-flash`

### Ã‰tapes :

1. **CareLink est dÃ©jÃ  lancÃ©** â†’ http://localhost:5173

2. **Allez dans Configuration** (menu gauche)

3. **Section IA - Configurez :**
   ```
   Provider : Google Gemini
   ModÃ¨le : gemini-2.5-flash
   ClÃ© API : AIzaSyBedSTR_DeOiWuGB0Fj33OprBfGjHewzrY
   ```

4. **Sauvegardez**

5. **Testez dans ChatDoctor** :
   - Posez une question : "J'ai mal Ã  la tÃªte"
   - Gemini devrait rÃ©pondre instantanÃ©ment !

---

## ğŸ INSTALLER BACKEND PYTHON ML (Optionnel)

Le backend Python donne des super-pouvoirs Ã  CareLink :
- Analyse ML sÃ©mantique des symptÃ´mes
- DÃ©tection interactions mÃ©dicaments
- Performance x10 avec cache

### Installation :

```bash
# Aller dans le dossier
cd "C:\Users\RK\Desktop\CareLink DEV\CareLink\services\ia-health"

# CrÃ©er environnement virtuel
python -m venv venv

# Activer (Windows)
venv\Scripts\activate

# Installer dÃ©pendances
pip install -r requirements.txt

# Lancer le service
python main.py
```

Le service dÃ©marre sur **http://localhost:8003**

### VÃ©rifier :
```bash
curl http://localhost:8003/health
```

Doit retourner : `{"status":"healthy"}`

---

## ğŸ¦™ INSTALLER OLLAMA (IA Locale Gratuite)

Ollama = IA 100% gratuite, illimitÃ©e, offline !

### Installation :

1. **TÃ©lÃ©charger :** https://ollama.ai/download

2. **Installer** (exe Windows)

3. **TÃ©lÃ©charger un modÃ¨le :**
   ```bash
   ollama pull llama2
   ```

4. **DÃ©marrer le serveur :**
   ```bash
   ollama serve
   ```

5. **Configurer dans CareLink :**
   ```
   Provider : Local (Ollama)
   ModÃ¨le : llama2
   Endpoint : http://localhost:11434
   ```

---

## ğŸ›ï¸ UTILISER MULTI-PROVIDER AVEC PRIORITÃ‰S

Configurez **plusieurs IA simultanÃ©ment** avec fallback automatique !

### Exemple de configuration :

**Config 1 - Gemini (PrioritÃ© 100 = Max)**
```
Nom : Gemini Principal
Provider : Google Gemini
ModÃ¨le : gemini-2.5-flash
ClÃ© API : AIzaSy...
PrioritÃ© : 100
Statut : Actif
```

**Config 2 - Claude (PrioritÃ© 50 = Backup)**
```
Nom : Claude Backup
Provider : Anthropic
ModÃ¨le : claude-3-5-sonnet
ClÃ© API : sk-ant-...
PrioritÃ© : 50
Statut : Actif
```

**Config 3 - Ollama (PrioritÃ© 10 = Offline)**
```
Nom : Ollama Offline
Provider : Local
ModÃ¨le : llama2
Endpoint : http://localhost:11434
PrioritÃ© : 10
Statut : Actif
```

### Fonctionnement :

1. CareLink **essaie d'abord Gemini** (prioritÃ© 100)
2. Si Gemini Ã©choue â†’ **fallback automatique sur Claude**
3. Si Claude Ã©choue â†’ **fallback sur Ollama local**

**RÃ©sultat :** DisponibilitÃ© 99.9% !

---

## ğŸ’° VOIR LES COÃ›TS API

Le tracking est **automatique** pour tous les appels API.

### Consulter les stats :

Dans la console dÃ©veloppeur (F12) :

```javascript
// Voir les statistiques 30 derniers jours
const stats = await apiUsageTracker.getStats(30);
console.log(stats);

// Voir l'historique
const history = await apiUsageTracker.getHistory(100);
console.log(history);
```

### RÃ©sultat :
```json
[
  {
    "provider": "google",
    "totalRequests": 145,
    "totalTokens": 125340,
    "totalCost": 0.00,  // Gemini gratuit !
    "avgResponseTime": 1247
  },
  {
    "provider": "openai",
    "totalRequests": 23,
    "totalTokens": 45890,
    "totalCost": 12.45  // 12.45â‚¬
  }
]
```

---

## ğŸ“Š DASHBOARD TEMPS RÃ‰EL

Le dashboard se rafraÃ®chit **automatiquement toutes les 30 secondes**.

### Pour l'utiliser :

Dans n'importe quel composant :

```typescript
import { useAutoRefresh, RefreshIntervals } from './hooks/useAutoRefresh';
import { realtimeStats } from './services/RealtimeStats';

function MonComposant() {
  const [stats, setStats] = useState(null);

  // Auto-refresh toutes les 30 secondes
  useAutoRefresh({
    interval: RefreshIntervals.NORMAL,
    onRefresh: async () => {
      const data = await realtimeStats.getOverview();
      setStats(data);
    }
  });

  return <div>Stats live : {JSON.stringify(stats)}</div>;
}
```

**Intervalles disponibles :**
- `REALTIME`: 5s (temps rÃ©el)
- `FAST`: 15s (alertes)
- `NORMAL`: 30s (dashboard)
- `SLOW`: 60s
- `VERY_SLOW`: 5 min

---

## ğŸ§ª TESTER BACKEND PYTHON ML

Si vous avez installÃ© le backend Python :

### Test manuel :

```bash
# Test health check
curl http://localhost:8003/health

# Test analyse symptÃ´mes
curl -X POST http://localhost:8003/analyze-symptoms \
  -H "Content-Type: application/json" \
  -d "{\"symptoms\":\"douleur thoracique et essoufflement\",\"context\":{\"age\":55}}"
```

### RÃ©sultat :
```json
{
  "severity": "emergency",
  "similar_conditions": [
    {
      "name": "Infarctus du myocarde",
      "similarity": 0.87
    }
  ],
  "recommendations": ["ğŸš¨ APPELEZ LE 15"]
}
```

### Utilisation dans CareLink :

```typescript
import { pythonHealthML } from './services/PythonHealthML';

const result = await pythonHealthML.analyzeSymptoms(
  "J'ai des palpitations",
  { age: 55 }
);

if (result.severity === 'emergency') {
  alert("ğŸš¨ URGENCE");
}
```

---

## ğŸ” SÃ‰CURITÃ‰ CLÃ‰S API

Toutes les clÃ©s API sont **automatiquement chiffrÃ©es en AES-256** avant stockage.

### VÃ©rifier :

1. Configurez une clÃ© dans CareLink
2. Ouvrez la console dÃ©veloppeur (F12)
3. Regardez le localStorage ou electron-store
4. Vous verrez : `a1b2c3d4:9f8e7d6c...` (chiffrÃ©)

**Impossible de dÃ©chiffrer sans la clÃ© maÃ®tresse !**

---

## ğŸ“ FICHIERS CRÃ‰Ã‰S/MODIFIÃ‰S

### Nouveaux fichiers :

```
src/services/
â”œâ”€â”€ encryption.ts               # â­ Chiffrement AES-256
â”œâ”€â”€ PythonHealthML.ts          # â­ Client Python ML
â”œâ”€â”€ RealtimeStats.ts           # â­ Stats temps rÃ©el
â””â”€â”€ APIUsageTracker.ts         # â­ Tracking usage

src/hooks/
â””â”€â”€ useAutoRefresh.ts          # â­ Hook auto-refresh

services/ia-health/
â”œâ”€â”€ main.py                    # â­ Backend FastAPI
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### Fichiers modifiÃ©s :

```
src/utils/aiProviders.ts       # â­ Multi-provider + tracking
```

---

## âš¡ QUICK TIPS

### Gemini est gratuit !

Utilisez-le autant que vous voulez :
- 15 requÃªtes/minute
- 1500 requÃªtes/jour
- 1M tokens/jour

### OpenAI coÃ»te cher

GPT-4o : ~0.01â‚¬ / 1000 tokens output
â†’ Mettez Gemini en prioritÃ© 100, OpenAI en prioritÃ© 50

### Ollama est 100% gratuit

Mais plus lent (~5-10s par rÃ©ponse vs 1-2s pour Gemini)
â†’ Parfait pour mode offline

---

## ğŸ†˜ BESOIN D'AIDE ?

### CareLink ne dÃ©marre pas ?

```bash
cd "C:\Users\RK\Desktop\CareLink DEV\CareLink"
npm run start
```

### Gemini ne rÃ©pond pas ?

1. VÃ©rifiez la clÃ© API est bien copiÃ©e
2. VÃ©rifiez le modÃ¨le : `gemini-2.5-flash`
3. Regardez la console (F12) pour les erreurs

### Backend Python ne dÃ©marre pas ?

```bash
# VÃ©rifier Python installÃ©
python --version

# RÃ©installer dÃ©pendances
pip install -r requirements.txt --force-reinstall

# Tester modÃ¨le
python -c "from sentence_transformers import SentenceTransformer; print('OK')"
```

### Ollama ne marche pas ?

```bash
# VÃ©rifier service
ollama list

# RedÃ©marrer
ollama serve
```

---

## ğŸ‰ C'EST PARTI !

CareLink est maintenant **suralimentÃ©** avec les modules MatchPro IA !

**Testez Gemini maintenant** et profitez de l'IA mÃ©dicale gratuite ! ğŸš€
